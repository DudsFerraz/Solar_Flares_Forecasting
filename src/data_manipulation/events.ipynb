{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup",
   "id": "daa9f0fdc5c40e7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:52:43.234542Z",
     "start_time": "2025-09-19T22:52:43.108992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "from typing import Sequence\n",
    "from src import util\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from pandas.errors import ParserWarning\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ],
   "id": "a3f95d3f070ebc3c",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:52:43.373620Z",
     "start_time": "2025-09-19T22:52:43.262499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "\n",
    "data_path = os.getenv(\"EVENTS_PATH\")\n",
    "csv_path = os.getenv(\"EVENTS_CSV_PATH\")\n",
    "data = {}\n",
    "\n",
    "begin_year = 1996\n",
    "end_year = 2024"
   ],
   "id": "d50d1616aa37ce95",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Read Files",
   "id": "cfbd74ce3bde7626"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DSD Functions",
   "id": "2483d7b6f65ec745"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:52:43.403138Z",
     "start_time": "2025-09-19T22:52:43.397775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_data_row_dsd(file_lines: list[str], year_) -> int | None :\n",
    "    for i, line in enumerate(file_lines):\n",
    "        if year_ >= 2001:\n",
    "            if  \"#------------------------\" in line.strip():\n",
    "                return i + 1\n",
    "        else:\n",
    "            if 'Date   10.7cm  Number   Hemis. Regions Field   Flux   C  M  X'  in line.strip():\n",
    "                return i + 1\n",
    "\n",
    "    return None"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:52:43.433432Z",
     "start_time": "2025-09-19T22:52:43.427353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_dsd(path_, year_) -> pd.DataFrame:\n",
    "    col_names = ['year', 'month', 'day', 'radio_flux_10.7cm', 'sunspot_number',\n",
    "                'sunspot_area', 'new_regions', 'mean_solar_field', 'goes_xray_bkgd_flux',\n",
    "                'flares_c', 'flares_m', 'flares_x', 'flares_optical_s', 'flares_optical_1',\n",
    "                'flares_optical_2', 'flares_optical_3']\n",
    "\n",
    "    col_specs = [(0, 4), (5, 7), (8, 10), (11, 18), (19, 25), (26, 33), (34, 40),\n",
    "                (41, 47), (48, 54), (55, 58), (59, 61), (62, 64), (65, 68),\n",
    "                (69, 71), (72, 74), (75, 77)]\n",
    "\n",
    "    if year_ <= 1996:\n",
    "        col_names[0] = 'day'\n",
    "        col_names[2] = 'year'\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", ParserWarning)\n",
    "\n",
    "        with open(path_, 'r', errors='ignore') as f:\n",
    "            all_lines = f.readlines()\n",
    "\n",
    "        data_row = find_data_row_dsd(all_lines, year_)\n",
    "        if data_row is None:\n",
    "            print(f\"AVISO: Cabeçalho DSD não encontrado em {path_}. Pulando arquivo.\")\n",
    "            return pd.DataFrame(columns=col_names)\n",
    "\n",
    "        data_list = all_lines[data_row:]\n",
    "        data_str = \"\".join(data_list)\n",
    "        data_str_buffer = io.StringIO(data_str)\n",
    "\n",
    "        return pd.read_fwf(data_str_buffer,\n",
    "                           names=col_names,\n",
    "                           na_values=[-999, '*'],\n",
    "                           col_specs=col_specs,\n",
    "                           index_col=False)"
   ],
   "id": "8865b02babdaa152",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:52:43.462116Z",
     "start_time": "2025-09-19T22:52:43.457421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_dsd(df_local):\n",
    "    month_map = {'jan':1, 'feb':2, 'mar':3, 'apr':4, 'may':5, 'jun':6, 'jul':7, 'aug':8, 'sep':9, 'oct':10, 'nov':11, 'dec':12}\n",
    "    cleaned_month = df_local['month'].astype(str).str.strip().str.lower()\n",
    "    cleaned_month = cleaned_month.replace(month_map)\n",
    "    numeric_month = pd.to_numeric(cleaned_month, errors='coerce')\n",
    "\n",
    "    numeric_year = pd.to_numeric(df_local['year'], errors='coerce')\n",
    "    corrected_year = numeric_year.apply(\n",
    "        lambda y_: y_ + 1900 if y_ < 100 else y_\n",
    "    )\n",
    "\n",
    "    df_local['ds'] = pd.to_datetime({'year': corrected_year,\n",
    "                                    'month': numeric_month,\n",
    "                                    'day': df_local['day']\n",
    "    })\n",
    "\n",
    "    df_local = df_local.set_index('ds')\n",
    "    df_local = df_local.drop(columns=['month', 'day', 'year'])\n",
    "    return df_local"
   ],
   "id": "8bcd48e4ad8e42d3",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Events Functions",
   "id": "27ffbfbdb2b56b33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:52:43.488033Z",
     "start_time": "2025-09-19T22:52:43.484601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_data_row_events(file_lines_, date_: pd.Timestamp) -> int | None:\n",
    "    for i, line in enumerate(file_lines_):\n",
    "        if date_ <= pd.to_datetime('1998-05-08'):\n",
    "            if  \"Reg#\" in line.strip():\n",
    "                return i + 1\n",
    "        else:\n",
    "            if \"#----------------------------------------------------------\" in line.strip():\n",
    "                return i + 1\n",
    "\n",
    "    return None"
   ],
   "id": "6e995464519119be",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:52:43.512133Z",
     "start_time": "2025-09-19T22:52:43.507763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_event_date(file_lines, date_: pd.Timestamp) -> pd.Timestamp | None:\n",
    "    for i, line in enumerate(file_lines):\n",
    "        if date_ <= pd.to_datetime('1998-05-08'):\n",
    "            if f\"EDITED EVENTS for {date_.year}\" in line.strip():\n",
    "                date_str = line.strip()[17:]\n",
    "                return pd.to_datetime(date_str)\n",
    "        else:\n",
    "            if f\":Date: {date_.year}\" in line.strip():\n",
    "                date_str = line.strip()[6:]\n",
    "                return pd.to_datetime(date_str)\n",
    "\n",
    "    return None"
   ],
   "id": "ca6bf4a3da793f1f",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:52:43.541398Z",
     "start_time": "2025-09-19T22:52:43.536670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_events_lines(path_, date_: pd.Timestamp) -> pd.DataFrame:\n",
    "    with open(path_, 'r', errors='ignore') as f:\n",
    "        file_lines = f.readlines()\n",
    "\n",
    "    data_row = find_data_row_events(file_lines, date_)\n",
    "    if data_row is None:\n",
    "        print(f\"AVISO: Cabeçalho de Eventos não encontrado em {path_}\")\n",
    "        return pd.DataFrame({'raw_line': []})\n",
    "\n",
    "    data_lines = [line.rstrip('\\n') for line in file_lines[data_row:]]\n",
    "\n",
    "    df = pd.DataFrame(data_lines, columns=['raw_line'])\n",
    "    df = df[~df['raw_line'].str.contains(\"NO EVENT REPORTS\", na=False)].copy()\n",
    "    df = df[df['raw_line'].str.strip() != ''].copy()\n",
    "\n",
    "    df['date'] = find_event_date(file_lines, date_)\n",
    "\n",
    "    return df"
   ],
   "id": "c08244df370c0b9d",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:52:43.565660Z",
     "start_time": "2025-09-19T22:52:43.562529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_timestamps(df_: pd.DataFrame, column_name_: str) -> pd.Series:\n",
    "    date_str_series = df_['date'].dt.strftime('%Y-%m-%d')\n",
    "    time_str_series = df_[column_name_]\n",
    "    full_datetime_str = date_str_series + ' ' + time_str_series\n",
    "\n",
    "    return pd.to_datetime(full_datetime_str, format='%Y-%m-%d %H%M', errors='coerce')"
   ],
   "id": "51ffa8a437fdc32c",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:52:43.591823Z",
     "start_time": "2025-09-19T22:52:43.586432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def nullify_invalid_time_patterns(df_: pd.DataFrame, columns_names_: Sequence[str], pattern_: re.Pattern[str]) -> pd.DataFrame:\n",
    "    df_ = df_.copy()\n",
    "\n",
    "    for column_name in columns_names_:\n",
    "        mask = df_[column_name].str.match(pattern_, na=False)\n",
    "        to_nullify = (~mask)\n",
    "        df_.loc[to_nullify, column_name] = np.nan\n",
    "\n",
    "    return df_"
   ],
   "id": "4d9e16d18b83df3e",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:52:43.604785Z",
     "start_time": "2025-09-19T22:52:43.598170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_events(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    final_cols = ['date','event', 'begin', 'max', 'end', 'obs', 'q', 'type', 'loc_frq', 'particulars', 'reg#']\n",
    "\n",
    "    if df_raw.empty:\n",
    "        return pd.DataFrame(columns=final_cols)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    na_values = ['','////']\n",
    "    df = df.replace(na_values, np.nan)\n",
    "\n",
    "    df['date'] = df_raw['date']\n",
    "    df['event_num'] = df_raw['raw_line'].str.slice(0, 5).str.strip()\n",
    "    df['event_plus'] = df_raw['raw_line'].str.slice(5, 11).str.strip()\n",
    "    df['begin'] = df_raw['raw_line'].str.slice(11, 18).str.strip()\n",
    "    df['max'] = df_raw['raw_line'].str.slice(18, 28).str.strip()\n",
    "    df['end'] = df_raw['raw_line'].str.slice(28, 34).str.strip()\n",
    "    df['obs'] = df_raw['raw_line'].str.slice(34, 39).str.strip()\n",
    "    df['q'] = df_raw['raw_line'].str.slice(39, 43).str.strip()\n",
    "    df['type'] = df_raw['raw_line'].str.slice(43, 48).str.strip()\n",
    "    df['loc_frq'] = df_raw['raw_line'].str.slice(48, 58).str.strip()\n",
    "    df['particulars'] = df_raw['raw_line'].str.slice(58, 76).str.strip()\n",
    "    df['reg#'] = df_raw['raw_line'].str.slice(76).str.strip()\n",
    "\n",
    "    df['event_plus'] = df['event_plus'].fillna('')\n",
    "    df['event'] = (df['event_num'] + df['event_plus']).str.replace(r'[ABU]','',regex=True).str.strip()\n",
    "\n",
    "    time_columns = ('begin', 'max', 'end')\n",
    "    pattern = re.compile(r'^\\d{4}$')\n",
    "    df = nullify_invalid_time_patterns(df, time_columns, pattern)\n",
    "\n",
    "    for column_name in time_columns:\n",
    "        df[column_name] = create_timestamps(df, column_name)\n",
    "    df['max'] = np.where(df['max'] < df['begin'], df['max']+pd.Timedelta(days=1), df['max'])\n",
    "    df['end'] = np.where(df['end'] < df['begin'], df['end']+pd.Timedelta(days=1), df['end'])\n",
    "\n",
    "    df = df.replace(na_values, np.nan)\n",
    "\n",
    "    return df[final_cols]"
   ],
   "id": "30c1b9023b014dd7",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Main",
   "id": "160cde8723b39c73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:58:58.075801Z",
     "start_time": "2025-09-19T22:52:43.638820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for y in range(begin_year, end_year+1):\n",
    "    data[y] = {}\n",
    "\n",
    "    year_dir = os.path.join(data_path,f\"{y}\")\n",
    "    if not os.path.isdir(year_dir):\n",
    "        print(f\"ERRO: Diretório não encontrado, pulando ano {y}\")\n",
    "        continue\n",
    "\n",
    "    dsd_file_name = f\"{y}_DSD.txt\"\n",
    "    dsd_file_path = os.path.join(year_dir,dsd_file_name)\n",
    "\n",
    "    df_day = read_dsd(dsd_file_path, y)\n",
    "    df_day = format_dsd(df_day)\n",
    "\n",
    "    data[y]['DSD'] = df_day\n",
    "    print(f\"success reading {y} DSD\")\n",
    "\n",
    "    events_dir = os.path.join(year_dir,f\"{y}_events\")\n",
    "    if not os.path.isdir(events_dir):\n",
    "        print(f\"ERRO: Diretório não encontrado, pulando ano {y}\")\n",
    "        continue\n",
    "\n",
    "    df_events_list = []\n",
    "    files_in_dir = set(os.listdir(events_dir))\n",
    "\n",
    "    for date in pd.date_range(f\"{y}-01-01\", f\"{y}-12-31\"):\n",
    "        m_str = date.strftime(\"%m\")\n",
    "        d_str = date.strftime(\"%d\")\n",
    "        file_name = f\"{y}{m_str}{d_str}events.txt\"\n",
    "\n",
    "\n",
    "        if file_name not in files_in_dir:\n",
    "            if date >= pd.to_datetime(\"1996-07-31\"):\n",
    "                print(f\"AVISO : Arquivo não encontrado, pulando {date}\")\n",
    "            continue\n",
    "\n",
    "        full_path = os.path.join(events_dir, file_name)\n",
    "        df_day = read_events_lines(full_path, date)\n",
    "        if df_day is not None and not df_day.empty:\n",
    "            df_events_list.append(df_day)\n",
    "\n",
    "    df_events = pd.concat(df_events_list, ignore_index=True)\n",
    "    df_events = format_events(df_events)\n",
    "    data[y]['events'] = df_events\n",
    "    print(f\"Success reading {y} events\")"
   ],
   "id": "ee7a46dd3a6de38c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success reading 1996 DSD\n",
      "AVISO : Arquivo não encontrado, pulando 1996-12-05 00:00:00\n",
      "Success reading 1996 events\n",
      "AVISO: Cabeçalho DSD não encontrado em G:\\My Drive\\Solar_Flares\\Data\\events\\raw\\1997\\1997_DSD.txt. Pulando arquivo.\n",
      "success reading 1997 DSD\n",
      "Success reading 1997 events\n",
      "AVISO: Cabeçalho DSD não encontrado em G:\\My Drive\\Solar_Flares\\Data\\events\\raw\\1998\\1998_DSD.txt. Pulando arquivo.\n",
      "success reading 1998 DSD\n",
      "Success reading 1998 events\n",
      "AVISO: Cabeçalho DSD não encontrado em G:\\My Drive\\Solar_Flares\\Data\\events\\raw\\1999\\1999_DSD.txt. Pulando arquivo.\n",
      "success reading 1999 DSD\n",
      "Success reading 1999 events\n",
      "AVISO: Cabeçalho DSD não encontrado em G:\\My Drive\\Solar_Flares\\Data\\events\\raw\\2000\\2000_DSD.txt. Pulando arquivo.\n",
      "success reading 2000 DSD\n",
      "Success reading 2000 events\n",
      "success reading 2001 DSD\n",
      "Success reading 2001 events\n",
      "success reading 2002 DSD\n",
      "Success reading 2002 events\n",
      "success reading 2003 DSD\n",
      "Success reading 2003 events\n",
      "success reading 2004 DSD\n",
      "Success reading 2004 events\n",
      "success reading 2005 DSD\n",
      "Success reading 2005 events\n",
      "success reading 2006 DSD\n",
      "Success reading 2006 events\n",
      "success reading 2007 DSD\n",
      "Success reading 2007 events\n",
      "success reading 2008 DSD\n",
      "Success reading 2008 events\n",
      "success reading 2009 DSD\n",
      "Success reading 2009 events\n",
      "success reading 2010 DSD\n",
      "Success reading 2010 events\n",
      "success reading 2011 DSD\n",
      "Success reading 2011 events\n",
      "success reading 2012 DSD\n",
      "Success reading 2012 events\n",
      "success reading 2013 DSD\n",
      "AVISO : Arquivo não encontrado, pulando 2013-12-31 00:00:00\n",
      "Success reading 2013 events\n",
      "success reading 2014 DSD\n",
      "Success reading 2014 events\n",
      "success reading 2015 DSD\n",
      "Success reading 2015 events\n",
      "success reading 2016 DSD\n",
      "Success reading 2016 events\n",
      "success reading 2017 DSD\n",
      "Success reading 2017 events\n",
      "success reading 2018 DSD\n",
      "AVISO : Arquivo não encontrado, pulando 2018-12-31 00:00:00\n",
      "Success reading 2018 events\n",
      "success reading 2019 DSD\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-01 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-02 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-03 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-04 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-05 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-06 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-07 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-08 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-09 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-10 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-11 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-12 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-13 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-14 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-15 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-16 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-17 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-18 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-19 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-20 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-21 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-22 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-23 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-24 00:00:00\n",
      "AVISO : Arquivo não encontrado, pulando 2019-01-25 00:00:00\n",
      "Success reading 2019 events\n",
      "success reading 2020 DSD\n",
      "AVISO : Arquivo não encontrado, pulando 2020-12-31 00:00:00\n",
      "Success reading 2020 events\n",
      "success reading 2021 DSD\n",
      "AVISO : Arquivo não encontrado, pulando 2021-12-31 00:00:00\n",
      "Success reading 2021 events\n",
      "success reading 2022 DSD\n",
      "Success reading 2022 events\n",
      "success reading 2023 DSD\n",
      "Success reading 2023 events\n",
      "success reading 2024 DSD\n",
      "AVISO : Arquivo não encontrado, pulando 2024-12-31 00:00:00\n",
      "Success reading 2024 events\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:58:58.128331Z",
     "start_time": "2025-09-19T22:58:58.116245Z"
    }
   },
   "cell_type": "code",
   "source": "data[1996]['DSD']",
   "id": "50c1308ed333460b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            radio_flux_10.7cm  sunspot_number  sunspot_area  new_regions  \\\n",
       "ds                                                                         \n",
       "1996-01-01               75.0              25            10            1   \n",
       "1996-01-02               75.0              34             0            0   \n",
       "1996-01-03               81.0              30           110            1   \n",
       "1996-01-04               86.0              48           220            1   \n",
       "1996-01-05               85.0              69           410            0   \n",
       "...                       ...             ...           ...          ...   \n",
       "1996-12-27               75.0               0             0            0   \n",
       "1996-12-28               74.0               0             0            0   \n",
       "1996-12-29               74.0               0             0            0   \n",
       "1996-12-30               73.0               0             0            0   \n",
       "1996-12-31               72.0               0             0            0   \n",
       "\n",
       "            mean_solar_field goes_xray_bkgd_flux  flares_c  flares_m  \\\n",
       "ds                                                                     \n",
       "1996-01-01               NaN                A1.2       NaN       NaN   \n",
       "1996-01-02              -1.0                A0.8       0.0       0.0   \n",
       "1996-01-03               NaN                A0.9       1.0       0.0   \n",
       "1996-01-04              -1.0                 NaN       0.0       0.0   \n",
       "1996-01-05               6.0                 NaN       1.0       0.0   \n",
       "...                      ...                 ...       ...       ...   \n",
       "1996-12-27               NaN                A0.8       0.0       0.0   \n",
       "1996-12-28               NaN                A0.6       0.0       0.0   \n",
       "1996-12-29               NaN                A0.8       0.0       0.0   \n",
       "1996-12-30               NaN                A0.8       0.0       0.0   \n",
       "1996-12-31               NaN                A0.7       0.0       0.0   \n",
       "\n",
       "            flares_x  flares_optical_s  flares_optical_1  flares_optical_2  \\\n",
       "ds                                                                           \n",
       "1996-01-01       NaN               NaN               NaN               NaN   \n",
       "1996-01-02       0.0               NaN               NaN               NaN   \n",
       "1996-01-03       0.0               NaN               NaN               NaN   \n",
       "1996-01-04       0.0               NaN               NaN               NaN   \n",
       "1996-01-05       0.0               NaN               NaN               NaN   \n",
       "...              ...               ...               ...               ...   \n",
       "1996-12-27       0.0               NaN               NaN               NaN   \n",
       "1996-12-28       0.0               NaN               NaN               NaN   \n",
       "1996-12-29       0.0               NaN               NaN               NaN   \n",
       "1996-12-30       0.0               NaN               NaN               NaN   \n",
       "1996-12-31       0.0               NaN               NaN               NaN   \n",
       "\n",
       "            flares_optical_3  \n",
       "ds                            \n",
       "1996-01-01               NaN  \n",
       "1996-01-02               NaN  \n",
       "1996-01-03               NaN  \n",
       "1996-01-04               NaN  \n",
       "1996-01-05               NaN  \n",
       "...                      ...  \n",
       "1996-12-27               NaN  \n",
       "1996-12-28               NaN  \n",
       "1996-12-29               NaN  \n",
       "1996-12-30               NaN  \n",
       "1996-12-31               NaN  \n",
       "\n",
       "[366 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radio_flux_10.7cm</th>\n",
       "      <th>sunspot_number</th>\n",
       "      <th>sunspot_area</th>\n",
       "      <th>new_regions</th>\n",
       "      <th>mean_solar_field</th>\n",
       "      <th>goes_xray_bkgd_flux</th>\n",
       "      <th>flares_c</th>\n",
       "      <th>flares_m</th>\n",
       "      <th>flares_x</th>\n",
       "      <th>flares_optical_s</th>\n",
       "      <th>flares_optical_1</th>\n",
       "      <th>flares_optical_2</th>\n",
       "      <th>flares_optical_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-01-01</th>\n",
       "      <td>75.0</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A1.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-02</th>\n",
       "      <td>75.0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>A0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-03</th>\n",
       "      <td>81.0</td>\n",
       "      <td>30</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-04</th>\n",
       "      <td>86.0</td>\n",
       "      <td>48</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>85.0</td>\n",
       "      <td>69</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-12-27</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-12-28</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-12-29</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-12-30</th>\n",
       "      <td>73.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-12-31</th>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>366 rows × 13 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exporting CSVs",
   "id": "67ec278e702b3598"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:58:58.324711Z",
     "start_time": "2025-09-19T22:58:58.206760Z"
    }
   },
   "cell_type": "code",
   "source": "util.create_dirs(csv_path, begin_year, end_year)",
   "id": "9957e2e91f035ac0",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-19T22:59:02.513636Z",
     "start_time": "2025-09-19T22:58:58.383302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for y in range(begin_year, end_year+1):\n",
    "    df_dsd = data[y]['DSD']\n",
    "    df_events = data[y]['events']\n",
    "\n",
    "    year_dir = os.path.join(csv_path,str(y))\n",
    "    df_dsd.to_csv(os.path.join(year_dir,f\"{y}_DSD.csv\"))\n",
    "    df_events.to_csv(os.path.join(year_dir,f\"{y}_events.csv\"), index=False)"
   ],
   "id": "24a902e39a36266b",
   "outputs": [],
   "execution_count": 81
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
