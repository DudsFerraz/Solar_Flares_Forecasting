{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup",
   "id": "daa9f0fdc5c40e7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "from typing import Sequence\n",
    "from src.py_src import util\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from pandas.errors import ParserWarning\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ],
   "id": "a3f95d3f070ebc3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "\n",
    "data_path = os.getenv(\"EVENTS_PATH\")\n",
    "csv_path = os.getenv(\"EVENTS_CSV_PATH\")\n",
    "data = {}\n",
    "\n",
    "begin_year = 1996\n",
    "end_year = 2024\n",
    "events_range = range(begin_year, end_year + 1)"
   ],
   "id": "d50d1616aa37ce95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Read Files",
   "id": "cfbd74ce3bde7626"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DSD Functions",
   "id": "2483d7b6f65ec745"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def find_data_row_dsd(file_lines: list[str], year_) -> int | None :\n",
    "    for i, line in enumerate(file_lines):\n",
    "        if year_ >= 2001:\n",
    "            if  \"#------------------------\" in line.strip():\n",
    "                return i + 1\n",
    "        else:\n",
    "            if 'Date   10.7cm  Number   Hemis. Regions Field   Flux   C  M  X'  in line.strip():\n",
    "                return i + 1\n",
    "\n",
    "    return None"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def read_dsd(path_, year_) -> pd.DataFrame:\n",
    "    col_names = ['year', 'month', 'day', 'radio_flux_10.7cm', 'sunspot_number',\n",
    "                'sunspot_area', 'new_regions', 'mean_solar_field', 'goes_xray_bkgd_flux',\n",
    "                'flares_c', 'flares_m', 'flares_x', 'flares_optical_s', 'flares_optical_1',\n",
    "                'flares_optical_2', 'flares_optical_3']\n",
    "\n",
    "    col_specs = [(0, 4), (5, 7), (8, 10), (11, 18), (19, 25), (26, 33), (34, 40),\n",
    "                (41, 47), (48, 54), (55, 58), (59, 61), (62, 64), (65, 68),\n",
    "                (69, 71), (72, 74), (75, 77)]\n",
    "\n",
    "    if year_ <= 1996:\n",
    "        col_names[0] = 'day'\n",
    "        col_names[2] = 'year'\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", ParserWarning)\n",
    "\n",
    "        with open(path_, 'r', errors='ignore') as f:\n",
    "            all_lines = f.readlines()\n",
    "\n",
    "        data_row = find_data_row_dsd(all_lines, year_)\n",
    "        if data_row is None:\n",
    "            print(f\"AVISO: Cabeçalho DSD não encontrado em {path_}. Pulando arquivo.\")\n",
    "            return pd.DataFrame(columns=col_names)\n",
    "\n",
    "        data_list = all_lines[data_row:]\n",
    "        data_str = \"\".join(data_list)\n",
    "        data_str_buffer = io.StringIO(data_str)\n",
    "\n",
    "        return pd.read_fwf(data_str_buffer,\n",
    "                           names=col_names,\n",
    "                           na_values=[-999, '*'],\n",
    "                           col_specs=col_specs,\n",
    "                           index_col=False)"
   ],
   "id": "8865b02babdaa152",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def format_dsd(df_) -> pd.DataFrame:\n",
    "    df_ = df_.copy()\n",
    "\n",
    "    month_map = {'jan':1, 'feb':2, 'mar':3, 'apr':4, 'may':5, 'jun':6, 'jul':7, 'aug':8, 'sep':9, 'oct':10, 'nov':11, 'dec':12}\n",
    "    cleaned_month = df_['month'].astype(str).str.strip().str.lower()\n",
    "    cleaned_month = cleaned_month.replace(month_map)\n",
    "    numeric_month = pd.to_numeric(cleaned_month, errors='coerce')\n",
    "\n",
    "    numeric_year = pd.to_numeric(df_['year'], errors='coerce')\n",
    "    corrected_year = numeric_year.apply(\n",
    "        lambda y_: y_ + 1900 if y_ < 100 else y_\n",
    "    )\n",
    "\n",
    "    df_['ds'] = pd.to_datetime({'year': corrected_year,\n",
    "                                    'month': numeric_month,\n",
    "                                    'day': df_['day']\n",
    "                                })\n",
    "\n",
    "    df_ = df_.set_index('ds')\n",
    "    df_ = df_.drop(columns=['month', 'day', 'year'])\n",
    "    return df_"
   ],
   "id": "8bcd48e4ad8e42d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Events Functions",
   "id": "27ffbfbdb2b56b33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def find_data_row_events(file_lines_, date_: pd.Timestamp) -> int | None:\n",
    "    for i, line in enumerate(file_lines_):\n",
    "        if date_ <= pd.to_datetime('1998-05-08'):\n",
    "            if  \"Reg#\" in line.strip():\n",
    "                return i + 1\n",
    "        else:\n",
    "            if \"#----------------------------------------------------------\" in line.strip():\n",
    "                return i + 1\n",
    "\n",
    "    return None"
   ],
   "id": "6e995464519119be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def find_event_date(file_lines, date_: pd.Timestamp) -> pd.Timestamp | None:\n",
    "    for i, line in enumerate(file_lines):\n",
    "        if date_ <= pd.to_datetime('1998-05-08'):\n",
    "            if f\"EDITED EVENTS for {date_.year}\" in line.strip():\n",
    "                date_str = line.strip()[17:]\n",
    "                return pd.to_datetime(date_str)\n",
    "        else:\n",
    "            if f\":Date: {date_.year}\" in line.strip():\n",
    "                date_str = line.strip()[6:]\n",
    "                return pd.to_datetime(date_str)\n",
    "\n",
    "    return None"
   ],
   "id": "ca6bf4a3da793f1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def read_events_lines(path_, date_: pd.Timestamp) -> pd.DataFrame:\n",
    "    with open(path_, 'r', errors='ignore') as f:\n",
    "        file_lines = f.readlines()\n",
    "\n",
    "    data_row = find_data_row_events(file_lines, date_)\n",
    "    if data_row is None:\n",
    "        print(f\"AVISO: Cabeçalho de Eventos não encontrado em {path_}\")\n",
    "        return pd.DataFrame({'raw_line': []})\n",
    "\n",
    "    data_lines = [line.rstrip('\\n') for line in file_lines[data_row:]]\n",
    "\n",
    "    df = pd.DataFrame(data_lines, columns=['raw_line'])\n",
    "    df = df[~df['raw_line'].str.contains(\"NO EVENT REPORTS\", na=False)].copy()\n",
    "    df = df[df['raw_line'].str.strip() != ''].copy()\n",
    "\n",
    "    df['date'] = find_event_date(file_lines, date_)\n",
    "\n",
    "    return df"
   ],
   "id": "c08244df370c0b9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_timestamps(df_: pd.DataFrame, column_name_: str) -> pd.Series:\n",
    "    date_str_series = df_['date'].dt.strftime('%Y-%m-%d')\n",
    "    time_str_series = df_[column_name_]\n",
    "    full_datetime_str = date_str_series + ' ' + time_str_series\n",
    "\n",
    "    return pd.to_datetime(full_datetime_str, format='%Y-%m-%d %H%M', errors='coerce')"
   ],
   "id": "51ffa8a437fdc32c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def nullify_invalid_time_patterns(df_: pd.DataFrame, columns_names_: Sequence[str], pattern_: re.Pattern[str]) -> pd.DataFrame:\n",
    "    df_ = df_.copy()\n",
    "\n",
    "    for column_name in columns_names_:\n",
    "        mask = df_[column_name].str.match(pattern_, na=False)\n",
    "        to_nullify = (~mask)\n",
    "        df_.loc[to_nullify, column_name] = np.nan\n",
    "\n",
    "    return df_"
   ],
   "id": "4d9e16d18b83df3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def format_events(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    final_cols = ['date','event', 'begin', 'max', 'end', 'obs', 'q', 'type', 'loc_frq', 'particulars', 'reg#']\n",
    "\n",
    "    if df_raw.empty:\n",
    "        return pd.DataFrame(columns=final_cols)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    na_values = ['','////']\n",
    "    df = df.replace(na_values, np.nan)\n",
    "\n",
    "    df['date'] = df_raw['date']\n",
    "    df['event_num'] = df_raw['raw_line'].str.slice(0, 5).str.strip()\n",
    "    df['event_plus'] = df_raw['raw_line'].str.slice(5, 11).str.strip()\n",
    "    df['begin'] = df_raw['raw_line'].str.slice(11, 18).str.strip()\n",
    "    df['max'] = df_raw['raw_line'].str.slice(18, 28).str.strip()\n",
    "    df['end'] = df_raw['raw_line'].str.slice(28, 34).str.strip()\n",
    "    df['obs'] = df_raw['raw_line'].str.slice(34, 39).str.strip()\n",
    "    df['q'] = df_raw['raw_line'].str.slice(39, 43).str.strip()\n",
    "    df['type'] = df_raw['raw_line'].str.slice(43, 48).str.strip()\n",
    "    df['loc_frq'] = df_raw['raw_line'].str.slice(48, 58).str.strip()\n",
    "    df['particulars'] = df_raw['raw_line'].str.slice(58, 76).str.strip()\n",
    "    df['reg#'] = df_raw['raw_line'].str.slice(76).str.strip()\n",
    "\n",
    "    df['event_plus'] = df['event_plus'].fillna('')\n",
    "    df['event'] = (df['event_num'] + df['event_plus']).str.replace(r'[ABU]','',regex=True).str.strip()\n",
    "\n",
    "    time_columns = ('begin', 'max', 'end')\n",
    "    pattern = re.compile(r'^\\d{4}$')\n",
    "    df = nullify_invalid_time_patterns(df, time_columns, pattern)\n",
    "\n",
    "    for column_name in time_columns:\n",
    "        df[column_name] = create_timestamps(df, column_name)\n",
    "    df['max'] = np.where(df['max'] < df['begin'], df['max']+pd.Timedelta(days=1), df['max'])\n",
    "    df['end'] = np.where(df['end'] < df['begin'], df['end']+pd.Timedelta(days=1), df['end'])\n",
    "\n",
    "    df = df.replace(na_values, np.nan)\n",
    "\n",
    "    return df[final_cols]"
   ],
   "id": "30c1b9023b014dd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Main",
   "id": "160cde8723b39c73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for y in range(begin_year, end_year+1):\n",
    "    data[y] = {}\n",
    "\n",
    "    year_dir = os.path.join(data_path,f\"{y}\")\n",
    "    if not os.path.isdir(year_dir):\n",
    "        print(f\"ERRO: Diretório não encontrado, pulando ano {y}\")\n",
    "        continue\n",
    "\n",
    "    dsd_file_name = f\"{y}_DSD.txt\"\n",
    "    dsd_file_path = os.path.join(year_dir,dsd_file_name)\n",
    "\n",
    "    df_day = read_dsd(dsd_file_path, y)\n",
    "    df_day = format_dsd(df_day)\n",
    "\n",
    "    data[y]['DSD'] = df_day\n",
    "    print(f\"success reading {y} DSD\")\n",
    "\n",
    "    events_dir = os.path.join(year_dir,f\"{y}_events\")\n",
    "    if not os.path.isdir(events_dir):\n",
    "        print(f\"ERRO: Diretório não encontrado, pulando ano {y}\")\n",
    "        continue\n",
    "\n",
    "    df_events_list = []\n",
    "    files_in_dir = set(os.listdir(events_dir))\n",
    "\n",
    "    for date in pd.date_range(f\"{y}-01-01\", f\"{y}-12-31\"):\n",
    "        m_str = date.strftime(\"%m\")\n",
    "        d_str = date.strftime(\"%d\")\n",
    "        file_name = f\"{y}{m_str}{d_str}events.txt\"\n",
    "\n",
    "\n",
    "        if file_name not in files_in_dir:\n",
    "            if date >= pd.to_datetime(\"1996-07-31\"):\n",
    "                print(f\"AVISO : Arquivo não encontrado, pulando {date}\")\n",
    "            continue\n",
    "\n",
    "        full_path = os.path.join(events_dir, file_name)\n",
    "        df_day = read_events_lines(full_path, date)\n",
    "        if df_day is not None and not df_day.empty:\n",
    "            df_events_list.append(df_day)\n",
    "\n",
    "    df_events = pd.concat(df_events_list, ignore_index=True)\n",
    "    df_events = format_events(df_events)\n",
    "    data[y]['events'] = df_events\n",
    "    print(f\"Success reading {y} events\")"
   ],
   "id": "ee7a46dd3a6de38c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data[1996]['DSD']",
   "id": "50c1308ed333460b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exporting CSVs",
   "id": "67ec278e702b3598"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "util.create_dirs(csv_path, events_range)",
   "id": "9957e2e91f035ac0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for y in range(begin_year, end_year+1):\n",
    "    df_dsd = data[y]['DSD']\n",
    "    df_events = data[y]['events']\n",
    "\n",
    "    year_dir = os.path.join(csv_path,str(y))\n",
    "    df_dsd.to_csv(os.path.join(year_dir,f\"{y}_DSD.csv\"))\n",
    "    df_events.to_csv(os.path.join(year_dir,f\"{y}_events.csv\"), index=False)"
   ],
   "id": "24a902e39a36266b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
